{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be02d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/topic_identifier/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore \n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a304d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the document\n",
    "loader = PyPDFLoader(\"/workspace/topic_identifier/data/Copy of TOT DISCIPLESHIP TEACHING MATERIAL (1).pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f33bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "#splitting the document into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 10_000, chunk_overlap = 500)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104868aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the prompt topic identifier\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an expert at summarizing document sections.\n",
    "Given the following page text:\n",
    "\n",
    "{page_text}\n",
    "\n",
    "Provide ONE short, clear topic title for this page.\n",
    "Return ONLY the topic string without quotes or extra text.\n",
    "    \"\"\"\n",
    ")\n",
    "model = OllamaLLM(model=\"gemma3:latest\")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f71618c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting  the topics json file from the output\n",
    "def extract_json_array(output):\n",
    "    # Look for the first valid JSON array in the output\n",
    "    match = re.search(r'\\[.*?\\]', output, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group())\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Matched text is not valid JSON\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"No JSON array found\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3590cf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sending chunk 1/70 to LLM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sending chunk 2/70 to LLM...\n",
      "\n",
      "Sending chunk 3/70 to LLM...\n",
      "\n",
      "Sending chunk 4/70 to LLM...\n",
      "\n",
      "Sending chunk 5/70 to LLM...\n",
      "\n",
      "Sending chunk 6/70 to LLM...\n",
      "\n",
      "Sending chunk 7/70 to LLM...\n",
      "\n",
      "Sending chunk 8/70 to LLM...\n",
      "\n",
      "Sending chunk 9/70 to LLM...\n",
      "\n",
      "Sending chunk 10/70 to LLM...\n",
      "\n",
      "Sending chunk 11/70 to LLM...\n",
      "\n",
      "Sending chunk 12/70 to LLM...\n",
      "\n",
      "Sending chunk 13/70 to LLM...\n",
      "\n",
      "Sending chunk 14/70 to LLM...\n",
      "\n",
      "Sending chunk 15/70 to LLM...\n",
      "\n",
      "Sending chunk 16/70 to LLM...\n",
      "\n",
      "Sending chunk 17/70 to LLM...\n",
      "\n",
      "Sending chunk 18/70 to LLM...\n",
      "\n",
      "Sending chunk 19/70 to LLM...\n",
      "\n",
      "Sending chunk 20/70 to LLM...\n",
      "\n",
      "Sending chunk 21/70 to LLM...\n",
      "\n",
      "Sending chunk 22/70 to LLM...\n",
      "\n",
      "Sending chunk 23/70 to LLM...\n",
      "\n",
      "Sending chunk 24/70 to LLM...\n",
      "\n",
      "Sending chunk 25/70 to LLM...\n",
      "\n",
      "Sending chunk 26/70 to LLM...\n",
      "\n",
      "Sending chunk 27/70 to LLM...\n",
      "\n",
      "Sending chunk 28/70 to LLM...\n",
      "\n",
      "Sending chunk 29/70 to LLM...\n",
      "\n",
      "Sending chunk 30/70 to LLM...\n",
      "\n",
      "Sending chunk 31/70 to LLM...\n",
      "\n",
      "Sending chunk 32/70 to LLM...\n",
      "\n",
      "Sending chunk 33/70 to LLM...\n",
      "\n",
      "Sending chunk 34/70 to LLM...\n",
      "\n",
      "Sending chunk 35/70 to LLM...\n",
      "\n",
      "Sending chunk 36/70 to LLM...\n",
      "\n",
      "Sending chunk 37/70 to LLM...\n",
      "\n",
      "Sending chunk 38/70 to LLM...\n",
      "\n",
      "Sending chunk 39/70 to LLM...\n",
      "\n",
      "Sending chunk 40/70 to LLM...\n",
      "\n",
      "Sending chunk 41/70 to LLM...\n",
      "\n",
      "Sending chunk 42/70 to LLM...\n",
      "\n",
      "Sending chunk 43/70 to LLM...\n",
      "\n",
      "Sending chunk 44/70 to LLM...\n",
      "\n",
      "Sending chunk 45/70 to LLM...\n",
      "\n",
      "Sending chunk 46/70 to LLM...\n",
      "\n",
      "Sending chunk 47/70 to LLM...\n",
      "\n",
      "Sending chunk 48/70 to LLM...\n",
      "\n",
      "Sending chunk 49/70 to LLM...\n",
      "\n",
      "Sending chunk 50/70 to LLM...\n",
      "\n",
      "Sending chunk 51/70 to LLM...\n",
      "\n",
      "Sending chunk 52/70 to LLM...\n",
      "\n",
      "Sending chunk 53/70 to LLM...\n",
      "\n",
      "Sending chunk 54/70 to LLM...\n",
      "\n",
      "Sending chunk 55/70 to LLM...\n",
      "\n",
      "Sending chunk 56/70 to LLM...\n",
      "\n",
      "Sending chunk 57/70 to LLM...\n",
      "\n",
      "Sending chunk 58/70 to LLM...\n",
      "\n",
      "Sending chunk 59/70 to LLM...\n",
      "\n",
      "Sending chunk 60/70 to LLM...\n",
      "\n",
      "Sending chunk 61/70 to LLM...\n",
      "\n",
      "Sending chunk 62/70 to LLM...\n",
      "\n",
      "Sending chunk 63/70 to LLM...\n",
      "\n",
      "Sending chunk 64/70 to LLM...\n",
      "\n",
      "Sending chunk 65/70 to LLM...\n",
      "\n",
      "Sending chunk 66/70 to LLM...\n",
      "\n",
      "Sending chunk 67/70 to LLM...\n",
      "\n",
      "Sending chunk 68/70 to LLM...\n",
      "\n",
      "Sending chunk 69/70 to LLM...\n",
      "\n",
      "Sending chunk 70/70 to LLM...\n"
     ]
    }
   ],
   "source": [
    "#creating the outlines\n",
    "sub_outlines = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    page_text = chunk.page_content\n",
    "    try:\n",
    "        print(f\"\\nSending chunk {i+1}/{len(chunks)} to LLM...\")\n",
    "        result = chain.invoke({\"page_text\": page_text})\n",
    "        # Parse the JSON output safely\n",
    "        try:\n",
    "            sub_outlines.append({\n",
    "                \"chunk_id\": i,\n",
    "                \"headings\": result\n",
    "            })\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to parse JSON from chunk {i+1}. Output was:\\n{result}\")\n",
    "            continue\n",
    "\n",
    "        time.sleep(1.5)  \n",
    "    except Exception as e:\n",
    "        print(f\"Error in chunk {i+1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf04fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtopic_dataframe\u001b[49m.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'topic_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "topic_dataframe = pd.DataFrame(sub_outlines)\n",
    "topic_dataframe.to_csv(\"topic_lists.csv\", index=False)\n",
    "print(\"Saved topic list to topic_lists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c12817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "160c8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use BGE embeddings (better than MiniLM)\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bfdded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3743/2781851287.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "#adding the embeddings to a vectorstore\n",
    "vectorstore = Chroma(\n",
    "    collection_name = \"test_documents\",\n",
    "    embedding_function = embedding_model,\n",
    "    persist_directory=\"./chroma_db\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17d84219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a retriever\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81b5b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore()  \n",
    "retriever = ParentDocumentRetriever(\n",
    "            vectorstore=vectorstore,\n",
    "            docstore=store,\n",
    "            child_splitter=child_splitter,\n",
    "            parent_splitter=parent_splitter\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cba4551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3743/1494616494.py:8: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "# Store documents with metadata\n",
    "texts = [c['text'] for c in tagged_chunks]\n",
    "metadatas = [{'chunk_id': c['chunk_id'], 'topic': c['topic']} for c in tagged_chunks]\n",
    "documents = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadatas)]\n",
    "\n",
    "# Add to vectorstore\n",
    "vectorstore.add_documents(documents)\n",
    "vectorstore.persist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
